{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN in pytorch\n",
    "\n",
    "The goal of this exercise is to implement DQN using pytorch and to apply it to the cartpole balancing problem. \n",
    "\n",
    "The code is adapted from the Pytorch tutorial: <https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -U gymnasium pygame swig\n",
    "    !pip install -U moviepy==1.0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym version: 1.0.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Default libraries\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# Gymnasium\n",
    "import gymnasium as gym\n",
    "print(\"gym version:\", gym.__version__)\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Select hardware: \n",
    "if torch.cuda.is_available(): # GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): # Metal (Macos)\n",
    "    device = torch.device(\"mps\")\n",
    "else: # CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip, ipython_display\n",
    "\n",
    "class GymRecorder(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper over moviepy to generate a .gif with the frames of a gym environment.\n",
    "    \n",
    "    The environment must have the render_mode `rgb_array_list`.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self._frames = []\n",
    "\n",
    "    def record(self, frames):\n",
    "        \"To be called at the end of an episode.\"\n",
    "        for frame in frames:\n",
    "            self._frames.append(np.array(frame))\n",
    "\n",
    "    def make_video(self, filename):\n",
    "        \"Generates the gif video.\"\n",
    "        directory = os.path.dirname(os.path.abspath(filename))\n",
    "        if not os.path.exists(directory):\n",
    "            os.mkdir(directory)\n",
    "        self.clip = ImageSequenceClip(list(self._frames), fps=self.env.metadata[\"render_fps\"])\n",
    "        self.clip.write_gif(filename, fps=self.env.metadata[\"render_fps\"], loop=0)\n",
    "        del self._frames\n",
    "        self._frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartpole balancing task\n",
    "\n",
    "We are going to use the Cartpole balancing problem, which can be loaded with:\n",
    "\n",
    "```python\n",
    "gym.make('CartPole-v0', render_mode=\"rgb_array_list\")\n",
    "```\n",
    "\n",
    "States have 4 continuous values (position and speed of the cart, angle and speed of the pole) and 2 discrete outputs (going left or right). The reward is +1 for each transition where the pole is still standing (angle of less than 30Â° with the vertical). \n",
    "\n",
    "In CartPole-v0, the episode ends when the pole fails or after 200 steps. In CartPole-v1, the maximum episode length is 500 steps, which is too long for us, so we stick to v0 here.\n",
    "\n",
    "The maximal (undiscounted) return is therefore 200. Can DQN learn this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return: 15.0\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0', render_mode=\"rgb_array_list\")\n",
    "recorder = GymRecorder(env)\n",
    "\n",
    "# Sample the initial state\n",
    "state, info = env.reset()\n",
    "\n",
    "# One episode:\n",
    "done = False\n",
    "return_episode = 0\n",
    "while not done:\n",
    "\n",
    "    # Select an action randomly\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Sample a single transition\n",
    "    next_state, reward, terminal, truncated, info = env.step(action)\n",
    "\n",
    "    # End of the episode\n",
    "    done = terminal or truncated\n",
    "\n",
    "    # Update undiscounted return\n",
    "    return_episode += reward\n",
    "    \n",
    "    # Go in the next state\n",
    "    state = next_state\n",
    "\n",
    "print(\"Return:\", return_episode)\n",
    "recorder.record(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"videos/cartpole_random.gif\"\n",
    "recorder.make_video(video)\n",
    "ipython_display(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value network in pytorch\n",
    "\n",
    "As the state in Cartpole has only four dimensions, we do not need a CNN for the value network. A simple MLP with a couple of hidden layers will be enough.\n",
    "\n",
    "**Q:** Create a MLP class in pytorch taking four inputs and two outputs (one Q-value per action), and two hidden layers of 128 neurons (you can change it later). If possible, make it parameterizable, i.e. have the constructor take in the number of inputs, outputs and hidden neurons. The activation function for the hidden layers should be ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"Value network for DQN on Cartpole.\"\n",
    "\n",
    "    def __init__(self, nb_observations, nb_hidden1, nb_hidden2, nb_actions):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Layers\n",
    "        self.fc1 = torch.nn.Linear(nb_observations, nb_hidden1)\n",
    "        self.fc2 = torch.nn.Linear(nb_hidden1, nb_hidden2)\n",
    "        self.fc3 = torch.nn.Linear(nb_hidden2, nb_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Create a network, an environment, get the initial state using `env.reset()` and pass it to the `forward()` method of your NN. What happens?\n",
    "\n",
    "Do not forget to send the network to your device, especially if you have a GPU. Create the network using something like:\n",
    "\n",
    "```python\n",
    "net = MLP(...).to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01285576 -0.02505752  0.00463476  0.01868387]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(state)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Predict the Q-values from the initial state\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m Q_values \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[0;32m~/Teaching/DeepReinforcementLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Teaching/DeepReinforcementLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Teaching/DeepReinforcementLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Create the value network\n",
    "net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Sample the initial state\n",
    "state, info = env.reset()\n",
    "print(state)\n",
    "\n",
    "# Predict the Q-values from the initial state\n",
    "Q_values = net.forward(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we need to cast the state vector into a pytorch tensor, pytorch does not do it automatically.\n",
    "\n",
    "To cast a numpy vector of shape (4,) into a tensor, one simply needs to call:\n",
    "\n",
    "```python\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "```\n",
    "\n",
    "The dtype must be set to `torch.float32` for floating numbers. Integers should be set to `torch.long`. Do not forget to send the tensor to your device if you plan to pass it to your network.\n",
    "\n",
    "**Q:** Pass the new tensor to your network. What is the shape of the output tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01986345 0.00116159 0.00450609 0.01564546] (4,)\n",
      "tensor([0.0199, 0.0012, 0.0045, 0.0156], device='mps:0') torch.Size([4])\n",
      "tensor([-0.0531, -0.0125], device='mps:0', grad_fn=<LinearBackward0>) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Create the value network\n",
    "net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Sample the initial state\n",
    "state, info = env.reset()\n",
    "print(state, state.shape)\n",
    "\n",
    "# Cast the state to a tensor\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "print(state, state.shape)\n",
    "\n",
    "# Predict the Q-values from the initial state\n",
    "Q_values = net.forward(state)\n",
    "print(Q_values, Q_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value network outputs one Q-value per action, great. Now, let's identify the **greedy** action, i.e. the one with the highest Q-value. The two actions expected by the cartpole environment are 0 and 1, i.e. the index of the element with the highest Q-value as a Python integer. \n",
    "\n",
    "Have a look at those two methods of `Tensor`:\n",
    "\n",
    "* ``Tensor.argmax``: <https://pytorch.org/docs/stable/generated/torch.argmax.html>\n",
    "* ``Tensor.item``: <https://pytorch.org/docs/stable/generated/torch.Tensor.item.html>\n",
    "\n",
    "**Q:** Find a way to obtain the index (as a Python integer) of the element with the highest value in the tensor of Q-values. Check that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy action: 1\n"
     ]
    }
   ],
   "source": [
    "greedy_action = Q_values.argmax().item()\n",
    "print(f\"Greedy action: {greedy_action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Create a dummy agent class (as in the previous exercises) storing a value network and acting using $\\epsilon$-greedy action selection. Add a ``test()``method running a few episodes and possibly recording them. \n",
    "\n",
    "The constructor should accept several hyperparameters, such as the `config` dictionary in the following skeleton:\n",
    "\n",
    "```python\n",
    "class RandomDQNAgent:\n",
    "    def __init__(self, env, config):\n",
    "    def act(self, state):\n",
    "    def test(self, nb_episodes, recorder=None):\n",
    "```\n",
    "\n",
    "but feel free to pass the hyperparameters one by one.\n",
    "\n",
    "To prepare ourselves, implement a schedule for `epsilon` in the `act()` method: epsilon should start at a high value of 0.9 and decrease exponentially to 0.05 for each action made. The value of epsilon follows this formula:\n",
    "\n",
    "$$\n",
    "    \\epsilon = 0.05 + (0.9 - 0.05) * \\exp ( - \\dfrac{t}{1000})\n",
    "$$\n",
    "\n",
    "where t is the number of steps since the start. 0.05, 0.9 and 1000 should be parameters of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDQNAgent:\n",
    "    \"\"\"\n",
    "    Random deep Q-learning agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env, config):\n",
    "\n",
    "        self.env = env\n",
    "        self.config = config\n",
    "        self.epsilon = self.config['eps_start']\n",
    "\n",
    "        # Number of actions\n",
    "        self.n_actions = self.env.action_space.n\n",
    "\n",
    "        # Number of states\n",
    "        self.state, info = self.env.reset()\n",
    "        self.n_observations = len(self.state)\n",
    "\n",
    "        # Value network\n",
    "        self.value_net = MLP(self.n_observations, config['nb_hidden'], config['nb_hidden'], self.n_actions).to(device)\n",
    "\n",
    "        self.steps_done = 0\n",
    "        \n",
    "    \n",
    "    def act(self, state):\n",
    "        \"Returns an action using epsilon-greedy action selection.\"\n",
    "\n",
    "        # Decay epsilon exponentially\n",
    "        self.epsilon = self.config['eps_end'] + (self.config['eps_start'] - self.config['eps_end']) * math.exp(-1. * self.steps_done / self.config['eps_decay'])\n",
    "\n",
    "        # Keep track of time\n",
    "        self.steps_done += 1\n",
    "    \n",
    "        # epsilon-greedy action selection\n",
    "        if rng.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return self.value_net(state).argmax().item()\n",
    "\n",
    "    \n",
    "    def test(self, nb_episodes, recorder=None):\n",
    "        \"Performs a test episode without exploration.\"\n",
    "        previous_epsilon = self.epsilon\n",
    "        self.epsilon = 0.0\n",
    "\n",
    "        for episode in range(nb_episodes):\n",
    "        \n",
    "            # Reset\n",
    "            state, _ = self.env.reset()\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "            # Sample the episode\n",
    "            done = False\n",
    "            return_episode = 0\n",
    "            while not done:                \n",
    "                action = self.act(state)\n",
    "                next_state, reward, terminal, truncated, info = self.env.step(action)\n",
    "                return_episode += reward\n",
    "                done = terminal or truncated\n",
    "                state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "\n",
    "            print(f\"Episode {episode}: return {return_episode}, epsilon: {self.epsilon:.4f}\")\n",
    "            \n",
    "        self.epsilon = previous_epsilon\n",
    "            \n",
    "        if recorder is not None:\n",
    "            recorder.record(self.env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: return 10.0, epsilon: 0.8924\n",
      "Episode 1: return 13.0, epsilon: 0.8815\n",
      "Episode 2: return 21.0, epsilon: 0.8642\n",
      "Episode 3: return 17.0, epsilon: 0.8505\n",
      "Episode 4: return 25.0, epsilon: 0.8307\n",
      "Episode 5: return 18.0, epsilon: 0.8168\n",
      "Episode 6: return 15.0, epsilon: 0.8054\n",
      "Episode 7: return 37.0, epsilon: 0.7780\n",
      "Episode 8: return 13.0, epsilon: 0.7686\n",
      "Episode 9: return 13.0, epsilon: 0.7593\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0', render_mode=\"rgb_array_list\")\n",
    "recorder = GymRecorder(env)\n",
    "\n",
    "# Hyperparameters\n",
    "config = {}\n",
    "config['nb_hidden'] = 128 # number of hidden neurons in each layer\n",
    "config['eps_start'] = 0.9 # starting value of epsilon\n",
    "config['eps_end'] = 0.05 # final value of epsilon\n",
    "config['eps_decay'] = 1000 # rate of exponential decay of epsilon, higher means a slower decay\n",
    "\n",
    "# Create the agent\n",
    "agent = RandomDQNAgent(env, config)\n",
    "\n",
    "# Make 10 evaluation episodes\n",
    "agent.test(10, recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"videos/cartpole-random2.gif\"\n",
    "recorder.make_video(video)\n",
    "ipython_display(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target network\n",
    "\n",
    "The original DQN algorithm implies two neural networks:\n",
    "\n",
    "1. The value network $Q_\\theta(s, a)$, learning to predict the Q-values for the current state.\n",
    "2. The target network $Q_{\\theta'}(s, a)$, used to predict the Q-values in the next state.\n",
    "\n",
    "The target network is a copy of the value network (in terms of structure and parameters), but the update occurs only from time to time.\n",
    "\n",
    "**Q:** Create two MLPs of the same size and predict the Q-values of a single state. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0853, -0.0911], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "tensor([-0.0374, -0.0259], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Create the value network\n",
    "value_net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Create the target network\n",
    "target_net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Sample the initial state\n",
    "state, _ = env.reset()\n",
    "\n",
    "# Cast the state to a tensor\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "# Predict the Q-values for both networks\n",
    "Q_value = value_net.forward(state)\n",
    "Q_target = target_net.forward(state)\n",
    "\n",
    "print(Q_value)\n",
    "print(Q_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the two MLPs are initialized using random parameters, so they are different. We need a method to copy the weights of a network into another one. \n",
    "\n",
    "It is fortunately very easy to save/load the parameters of a pytorch network:\n",
    "\n",
    "```python\n",
    "params = net.state_dict()\n",
    "net.load_state_dict(params)\n",
    "```\n",
    "\n",
    "**Q:** Apply these methods to update the weights of the target network with the value one. Check that they now predict the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0048, -0.0229], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "tensor([-0.0048, -0.0229], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Create the value network\n",
    "value_net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Create the target network\n",
    "target_net = MLP(env.observation_space.shape[0], 128, 128, env.action_space.n).to(device)\n",
    "\n",
    "# Update the target network\n",
    "target_net.load_state_dict(value_net.state_dict())\n",
    "\n",
    "# Sample the initial state\n",
    "state, _ = env.reset()\n",
    "\n",
    "# Cast the state to a tensor\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "# Predict the Q-values for both networks\n",
    "Q_value = value_net.forward(state)\n",
    "Q_target = target_net.forward(state)\n",
    "\n",
    "print(Q_value)\n",
    "print(Q_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay Memory\n",
    "\n",
    "The second important component of DQN is the experience replay memory (ERM) or replay buffer. It is a limited size buffer that can store $(s, a, r, s', d)$ transitions, where $d$ is a boolean indicating whether the next state $s'$ is terminal or not (in gymnasium, this is the boolean `done = terminal or truncated`).\n",
    "\n",
    "Below is a simple implementation of an ERM. The important data structure here is `deque` (double-ended queue) which behaves like a list when `append()` is called, until its capacity is reached (`maxlen`), in which case new elements overwrite older ones. \n",
    "\n",
    "`batch = sample(batch_size)` randomly samples a minibatch from the ERM and returns a structure of $(s, a, r, s', d)$ transitions, nicely casted into pytorch tensors. These tensors are accessed with `batch.state`, `batch.action`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named tuples are fancy dictionaries\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \"Simple Experience Replay Memory using uniform sampling.\"\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        \"Appends a transition (s, a, r, s', done) to the buffer.\"\n",
    "\n",
    "        # Get numpy arrays even if it is a torch tensor\n",
    "        if isinstance(state, (torch.Tensor,)): state = state.numpy(force=True)\n",
    "        if isinstance(next_state, (torch.Tensor,)): next_state = next_state.numpy(force=True)\n",
    "        \n",
    "        # Append to the buffer\n",
    "        self.memory.append(Transition(state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"Returns a minibatch of (s, a, r, s', done)\"\n",
    "\n",
    "        # Sample the batch\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        # Transpose the batch.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        # Cast to tensors\n",
    "        states = torch.tensor(batch.state, dtype=torch.float32, device=device)\n",
    "        actions = torch.tensor(batch.action, dtype=torch.long, device=device)\n",
    "        rewards = torch.tensor(batch.reward, dtype=torch.float32, device=device)\n",
    "        next_states = torch.tensor(batch.next_state, dtype=torch.float32, device=device)\n",
    "        dones = torch.tensor(batch.done, dtype=torch.bool, device=device)\n",
    "\n",
    "        return Transition(states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Modify your random DQN agent so that it stores a replay buffer of capacity 10000 and appends all transitions into it. Do a few episodes, sample a small minibatch and have a look at the data you obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDQNAgent:\n",
    "    \"\"\"\n",
    "    Random deep Q-learning agent with memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env, config):\n",
    "\n",
    "        self.env = env\n",
    "        self.config = config\n",
    "        self.epsilon = self.config['eps_start']\n",
    "\n",
    "        # Number of actions\n",
    "        self.n_actions = self.env.action_space.n\n",
    "\n",
    "        # Number of states\n",
    "        self.state, info = self.env.reset()\n",
    "        self.n_observations = len(self.state)\n",
    "\n",
    "        # Value network\n",
    "        self.value_net = MLP(self.n_observations, config['nb_hidden'], config['nb_hidden'], self.n_actions).to(device)\n",
    "\n",
    "        # Replay buffer\n",
    "        self.memory = ReplayMemory(capacity=1000)\n",
    "\n",
    "        self.steps_done = 0\n",
    "        \n",
    "    \n",
    "    def act(self, state):\n",
    "        \"Returns an action using epsilon-greedy action selection.\"\n",
    "\n",
    "        # Decay epsilon exponentially\n",
    "        self.epsilon = self.config['eps_end'] + (self.config['eps_start'] - self.config['eps_end']) * math.exp(-1. * self.steps_done / self.config['eps_decay'])\n",
    "\n",
    "        # Keep track of time\n",
    "        self.steps_done += 1\n",
    "    \n",
    "        # epsilon-greedy action selection\n",
    "        if rng.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return self.value_net(state).argmax().item()\n",
    "\n",
    "    \n",
    "    def test(self, nb_episodes, recorder=None):\n",
    "        \"Performs a test episode without exploration.\"\n",
    "        previous_epsilon = self.epsilon\n",
    "        self.epsilon = 0.0\n",
    "\n",
    "        for episode in range(nb_episodes):\n",
    "        \n",
    "            # Reset\n",
    "            state, _ = self.env.reset()\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "            # Sample the episode\n",
    "            done = False\n",
    "            return_episode = 0\n",
    "            while not done:                \n",
    "                action = self.act(state)\n",
    "                next_state, reward, terminal, truncated, info = self.env.step(action)\n",
    "                return_episode += reward\n",
    "                done = terminal or truncated\n",
    "                \n",
    "                # Append the transition to the replay buffer\n",
    "                self.memory.append(state, action, reward, next_state, done)\n",
    "\n",
    "                state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "\n",
    "            print(f\"Episode {episode}: return {return_episode}, epsilon: {self.epsilon:.4f}\")\n",
    "            \n",
    "        self.epsilon = previous_epsilon\n",
    "            \n",
    "        if recorder is not None:\n",
    "            recorder.record(self.env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: return 31.0, epsilon: 0.8749\n",
      "Episode 1: return 18.0, epsilon: 0.8602\n",
      "Episode 2: return 11.0, epsilon: 0.8513\n",
      "Episode 3: return 17.0, epsilon: 0.8378\n",
      "Episode 4: return 24.0, epsilon: 0.8191\n",
      "Episode 5: return 14.0, epsilon: 0.8084\n",
      "Episode 6: return 15.0, epsilon: 0.7971\n",
      "Episode 7: return 24.0, epsilon: 0.7794\n",
      "Episode 8: return 10.0, epsilon: 0.7722\n",
      "Episode 9: return 15.0, epsilon: 0.7614\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Hyperparameters\n",
    "config = {}\n",
    "config['nb_hidden'] = 128 # number of hidden neurons in each layer\n",
    "config['eps_start'] = 0.9 # starting value of epsilon\n",
    "config['eps_end'] = 0.05 # final value of epsilon\n",
    "config['eps_decay'] = 1000 # rate of exponential decay of epsilon, higher means a slower decay\n",
    "config['buffer_limit'] = 1000 # maximum number of transitions in the replay buffer\n",
    "\n",
    "# Create the agent\n",
    "agent = RandomDQNAgent(env, config)\n",
    "\n",
    "# Make 10 evaluation episodes\n",
    "agent.test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: torch.Size([10, 4]) tensor([[-6.2359e-02, -5.9088e-01,  3.3010e-02,  8.2792e-01],\n",
      "        [ 7.3589e-04,  1.8508e-01,  1.3062e-03, -2.8565e-01],\n",
      "        [-1.4464e-01, -7.7019e-01,  1.7364e-01,  1.1378e+00],\n",
      "        [ 4.1733e-02, -1.7907e-01,  4.6711e-02,  3.2569e-01],\n",
      "        [-1.6944e-01, -4.0909e-01,  1.9894e-01,  8.4437e-01],\n",
      "        [ 2.2588e-02,  1.8622e-01, -3.3669e-02, -3.1102e-01],\n",
      "        [-8.0306e-02, -5.5690e-01,  1.4338e-01,  1.1254e+00],\n",
      "        [ 3.8152e-02, -3.7482e-01,  5.3225e-02,  6.3273e-01],\n",
      "        [-1.6004e-01, -9.6710e-01,  1.9640e-01,  1.4795e+00],\n",
      "        [-5.3454e-02,  2.8487e-02, -6.9843e-03, -6.2012e-02]], device='mps:0')\n",
      "Actions: torch.Size([10]) tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "Rewards: torch.Size([10]) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='mps:0')\n",
      "Next states: torch.Size([10, 4]) tensor([[-0.0742, -0.3962,  0.0496,  0.5458],\n",
      "        [ 0.0044, -0.0101, -0.0044,  0.0074],\n",
      "        [-0.1600, -0.9671,  0.1964,  1.4795],\n",
      "        [ 0.0382, -0.3748,  0.0532,  0.6327],\n",
      "        [-0.1776, -0.6063,  0.2158,  1.1924],\n",
      "        [ 0.0263, -0.0084, -0.0399, -0.0291],\n",
      "        [-0.0914, -0.7536,  0.1659,  1.4594],\n",
      "        [ 0.0307, -0.5706,  0.0659,  0.9417],\n",
      "        [-0.1794, -1.1640,  0.2260,  1.8265],\n",
      "        [-0.0529, -0.1665, -0.0082,  0.2285]], device='mps:0')\n",
      "Dones: torch.Size([10]) tensor([False, False, False, False,  True, False, False, False,  True, False],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Sample the ERM\n",
    "batch = agent.memory.sample(10)\n",
    "\n",
    "print(\"States:\", batch.state.shape, batch.state)\n",
    "print(\"Actions:\", batch.action.shape, batch.action)\n",
    "print(\"Rewards:\", batch.reward.shape, batch.reward)\n",
    "print(\"Next states:\", batch.next_state.shape, batch.next_state)\n",
    "print(\"Dones:\", batch.done.shape, batch.done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Use the value network stored into your agent to predict the Q-values of all actions for the states contained in the minibatch. Do NOT use a for loop. Check the size of the resulting tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n",
      "tensor([[ 0.0274, -0.0792],\n",
      "        [ 0.0498, -0.0576],\n",
      "        [ 0.0230, -0.0945],\n",
      "        [ 0.0431, -0.0527],\n",
      "        [ 0.0483, -0.0747],\n",
      "        [ 0.0498, -0.0592],\n",
      "        [ 0.0358, -0.0745],\n",
      "        [ 0.0410, -0.0578],\n",
      "        [ 0.0032, -0.1031],\n",
      "        [ 0.0528, -0.0713]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Q_values = agent.value_net.forward(batch.state)\n",
    "\n",
    "print(Q_values.shape)\n",
    "print(Q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** The previous tensors returns the value of all actions in those visited states. We now want only the Q-value of action that was taken (whose index is in `batch.action`). The resulting tensor should therefore a vector of length `batch_size`. How do we do that?\n",
    "\n",
    "*Hint:* it would take months of practice to master all the indexing methods available in pytorch: <https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining>. Meanwhile, numpy-style indexing could be useful. Check what the following statements do:\n",
    "\n",
    "```python\n",
    "N = 10\n",
    "A = torch.randn((N, 2))\n",
    "B = torch.randint(0, 2, (N,))\n",
    "C = A[range(N), B]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0274, -0.0792],\n",
      "        [ 0.0498, -0.0576],\n",
      "        [ 0.0230, -0.0945],\n",
      "        [ 0.0431, -0.0527],\n",
      "        [ 0.0483, -0.0747],\n",
      "        [ 0.0498, -0.0592],\n",
      "        [ 0.0358, -0.0745],\n",
      "        [ 0.0410, -0.0578],\n",
      "        [ 0.0032, -0.1031],\n",
      "        [ 0.0528, -0.0713]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "tensor([-0.0792,  0.0498,  0.0230,  0.0431,  0.0483,  0.0498,  0.0358,  0.0410,\n",
      "         0.0032,  0.0528], device='mps:0', grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(Q_values)\n",
    "print(batch.action)\n",
    "Q_taken = Q_values[range(10), batch.action]\n",
    "print(Q_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN agent\n",
    "\n",
    "Good, we should now have all the elementary bricks to create our DQN agent. \n",
    "\n",
    "Reminder from the lecture:\n",
    "\n",
    "---\n",
    "\n",
    "* Initialize value network $Q_{\\theta}$ and target network $Q_{\\theta'}$.\n",
    "\n",
    "* Initialize experience replay memory $\\mathcal{D}$ of maximal size $N$.\n",
    "\n",
    "* for $t \\in [0, T_\\text{total}]$:\n",
    "\n",
    "    * Select an action $a_t$ based on $Q_\\theta(s_t, a)$ ($\\epsilon$-greedy), observe $s_{t+1}$ and $r_{t+1}$.\n",
    "\n",
    "    * Store $(s_t, a_t, r_{t+1}, s_{t+1})$ in the experience replay memory.\n",
    "\n",
    "    * Every $T_\\text{train}$ steps:\n",
    "\n",
    "        * Sample a minibatch $\\mathcal{D}_s$ randomly from $\\mathcal{D}$.\n",
    "\n",
    "        * For each transition $(s_k, a_k, r_k, s'_k)$ in the minibatch:\n",
    "\n",
    "            * Compute the target value $t_k = r_k + \\gamma \\, \\max_{a'} Q_{\\theta'}(s'_k, a')$ using the target network.\n",
    "\n",
    "        * Update the value network $Q_{\\theta}$ on $\\mathcal{D}_s$ to minimize:\n",
    "\n",
    "    $$\\mathcal{L}(\\theta) = \\mathbb{E}_{\\mathcal{D}_s}[(t_k - Q_\\theta(s_k, a_k))^2]$$\n",
    "\n",
    "    * Every $T_\\text{target}$ steps:\n",
    "\n",
    "        * Update target network: $\\theta' \\leftarrow \\theta$.\n",
    "---\n",
    "\n",
    "Create a DQN agent class inspired from the notebooks on MC or TD. The constructor should create the value and target networks, and make sure that their parameters are the same. It also creates an empty replay buffer. \n",
    "\n",
    "The `act()` method implements $\\epsilon$-greedy action selection, with an exponentially decaying schedule for $\\epsilon$. The greedy action is read from the value network.\n",
    "\n",
    "The `train()` and `test()` methods run training and test episodes as usual, with optional rendering. The train method should return (or store in the object) the return of each episode (its length) so we can plot it at the end. \n",
    "\n",
    "The main difficulty will be the `update()` method, where learning is supposed to happen. It should sample a minibatch from the replay memory, compute a vector of Bellman targets $r_t + \\gamma \\, \\max_a Q(s_{t+1}, a)$ for each transition in the batch, compute the loss function (mse between these targets and the predicted Q-values), backpropagate the gradients and apply the optimizer (Adam, but feel free to pick your preferred optimizer). Refer to the previous notebook on pytorch if you do not know how to do that.\n",
    "\n",
    "The main tricky part is when $V(s_{t+1})$ has to be predicted by the **target** network. You do not want the target network to learn from the minibatch, so it should not compute the corresponding gradients to save computational time. You can make sure that the target network is purely in inference mode with the following context:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    next_Q_values = target_net(batch.next_state)\n",
    "```\n",
    "\n",
    "Of course you want the Q-value of the greedy action in the next state, not the vector of all Q-values, so check the doc of `Tensor.max()`. \n",
    "\n",
    "Importantly, when the next state $s'$ is terminal (either the agent failed or the 200 steps are over), the Bellman target should be simply $r_t$ instead of $r_t + \\gamma \\, \\max_a Q(s_{t+1}, a)$, as no action will be taken in the next state. This is why we saved the booleans `done` were saved in the replay buffer. As they are boolean, you can use them for indexing:\n",
    "\n",
    "```python\n",
    "Q = torch.randn((batch_size,))\n",
    "Q[batch.dones] = 0.0\n",
    "```\n",
    "\n",
    "A minor detail: do not start learning until the replay buffer is full enough, otherwise you will not fill your minibatch. Usually, there is no learning until the buffer contains two or three times the batch size. Use `len(memory)` to know the current number of stored transitions.\n",
    "\n",
    "Here is a set of suggested hyperparameters to help you start. Of course, it is strongly advised to modify them and observe their influence, but it depends on the remaining time.\n",
    "\n",
    "* $\\gamma = 0.99$.\n",
    "* MLP with two layers of 128 neurons, Adam optimizer with a fixed learning rate of 0.001.\n",
    "* Replay buffer of maximum capacity 10000, batch size of 128.\n",
    "* Target network updated every 120 steps.\n",
    "* Epsilon-greedy action selection, with the schedule:\n",
    "\n",
    "$$\n",
    "    \\epsilon = 0.05 + (0.9 - 0.05) * \\exp ( - \\dfrac{t}{1000})\n",
    "$$\n",
    "\n",
    "where $t$ is the total number of steps.\n",
    "\n",
    "\n",
    "**Q:** Train a DQN on cartpole for 250 episodes. How would you characterize the learning process (speed, stability, etc.). If possible, do several runs. Vary the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"DQN agent.\"\n",
    "    \n",
    "    def __init__(self, env, config):\n",
    "\n",
    "        # Parameters\n",
    "        self.env = env\n",
    "        self.config = config\n",
    "\n",
    "        # Number of actions\n",
    "        self.n_actions = self.env.action_space.n\n",
    "\n",
    "        # Number of states\n",
    "        self.state, info = self.env.reset()\n",
    "        self.n_observations = len(self.state)\n",
    "\n",
    "        # Value network\n",
    "        self.value_net = MLP(self.n_observations, config['nb_hidden'], config['nb_hidden'], self.n_actions).to(device)\n",
    "\n",
    "        # Target network\n",
    "        self.target_net = MLP(self.n_observations, config['nb_hidden'], config['nb_hidden'], self.n_actions).to(device)\n",
    "\n",
    "        # Copy the value weights into the target network\n",
    "        self.target_net.load_state_dict(self.value_net.state_dict())\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.value_net.parameters(), lr=self.config['learning_rate'])\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_function = torch.nn.MSELoss()\n",
    "        \n",
    "        # Replay buffer\n",
    "        self.memory = ReplayMemory(self.config['buffer_limit'])\n",
    "\n",
    "        self.steps_done = 0\n",
    "        self.episode_durations = []\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        # Decay epsilon exponentially\n",
    "        self.epsilon = self.config['eps_end'] + (self.config['eps_start'] - self.config['eps_end']) * math.exp(-1. * self.steps_done / self.config['eps_decay'])\n",
    "\n",
    "        # Keep track of time\n",
    "        self.steps_done += 1\n",
    "    \n",
    "        # epsilon-greedy action selection\n",
    "        if rng.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return self.value_net(state).argmax(dim=0).item()\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Only learn when the replay buffer is full enough\n",
    "        if len(self.memory) < 2 * self.config['batch_size']:\n",
    "            return\n",
    "        \n",
    "        # Sample a batch\n",
    "        batch = self.memory.sample(self.config['batch_size'])\n",
    "\n",
    "        # Compute Q(s_t, a) with the current value network.\n",
    "        Q_values = self.value_net(batch.state)[range(self.config['batch_size']), batch.action]\n",
    "        \n",
    "        # Compute Q(s_{t+1}, a*) for all next states.\n",
    "        # If the next state is terminal, set the value to zero.\n",
    "        # Do not compute gradients.\n",
    "        with torch.no_grad():\n",
    "            next_Q_values = self.target_net(batch.next_state).max(dim=1).values\n",
    "            next_Q_values[batch.done] = 0.0\n",
    "\n",
    "        # Compute the target Q values\n",
    "        targets = (next_Q_values * self.config['gamma']) + batch.reward\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_function(Q_values, targets)\n",
    "\n",
    "        # Reinitialize the gradients\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # In-place gradient clipping (optional)\n",
    "        #torch.nn.utils.clip_grad_value_(self.value_net.parameters(), 100)\n",
    "\n",
    "        # Optimizer step\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        \n",
    "        for i_episode in range(num_episodes):\n",
    "\n",
    "            tstart = time.time()\n",
    "\n",
    "            # Initialize the environment and get its state\n",
    "            state, _ = self.env.reset()\n",
    "\n",
    "            # Transform the state into a tensor\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "            done = False\n",
    "            steps_episode = 0\n",
    "            while not done:\n",
    "                \n",
    "                # Select an action\n",
    "                action = self.act(state)\n",
    "                \n",
    "                # Perform the action\n",
    "                next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                \n",
    "                # Terminal state\n",
    "                done = terminated or truncated\n",
    "\n",
    "                # Store the transition in memory\n",
    "                self.memory.append(state, action, reward, next_state, done)\n",
    "\n",
    "                # Move to the next state\n",
    "                state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "\n",
    "                # Perform one step of the optimization (on the policy network)\n",
    "                self.update()\n",
    "\n",
    "                # Update of the target network's weights\n",
    "                if self.steps_done % self.config['target_update_period'] == 0:\n",
    "                    self.target_net.load_state_dict(self.value_net.state_dict())\n",
    "\n",
    "                # Finish episode\n",
    "                steps_episode += 1\n",
    "                if done:\n",
    "                    self.episode_durations.append(steps_episode)\n",
    "                    print(f\"Episode {i_episode+1}, duration {steps_episode}, epsilon {self.epsilon:.4f} done in {time.time() - tstart}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, duration 19, epsilon 0.8848 done in 0.010528087615966797\n",
      "Episode 2, duration 29, epsilon 0.8610 done in 0.016314029693603516\n",
      "Episode 3, duration 32, epsilon 0.8354 done in 0.018161296844482422\n",
      "Episode 4, duration 28, epsilon 0.8137 done in 0.015803813934326172\n",
      "Episode 5, duration 12, epsilon 0.8046 done in 0.0073490142822265625\n",
      "Episode 6, duration 15, epsilon 0.7934 done in 0.00738978385925293\n",
      "Episode 7, duration 16, epsilon 0.7816 done in 0.009552001953125\n",
      "Episode 8, duration 13, epsilon 0.7722 done in 0.006394147872924805\n",
      "Episode 9, duration 12, epsilon 0.7635 done in 0.0055730342864990234\n",
      "Episode 10, duration 9, epsilon 0.7571 done in 0.005897998809814453\n",
      "Episode 11, duration 23, epsilon 0.7411 done in 0.011080026626586914\n",
      "Episode 12, duration 28, epsilon 0.7220 done in 0.01707315444946289\n",
      "Episode 13, duration 18, epsilon 0.7100 done in 0.011223793029785156\n",
      "Episode 14, duration 38, epsilon 0.6854 done in 0.5081887245178223\n",
      "Episode 15, duration 12, epsilon 0.6778 done in 0.08037090301513672\n",
      "Episode 16, duration 16, epsilon 0.6678 done in 0.10638308525085449\n",
      "Episode 17, duration 17, epsilon 0.6574 done in 0.12128686904907227\n",
      "Episode 18, duration 11, epsilon 0.6508 done in 0.07467079162597656\n",
      "Episode 19, duration 14, epsilon 0.6424 done in 0.09404802322387695\n",
      "Episode 20, duration 13, epsilon 0.6348 done in 0.09186387062072754\n",
      "Episode 21, duration 22, epsilon 0.6221 done in 0.15014410018920898\n",
      "Episode 22, duration 27, epsilon 0.6068 done in 0.1894230842590332\n",
      "Episode 23, duration 15, epsilon 0.5985 done in 0.09884095191955566\n",
      "Episode 24, duration 22, epsilon 0.5866 done in 0.1490309238433838\n",
      "Episode 25, duration 16, epsilon 0.5781 done in 0.11019229888916016\n",
      "Episode 26, duration 14, epsilon 0.5707 done in 0.09550905227661133\n",
      "Episode 27, duration 19, epsilon 0.5609 done in 0.1321086883544922\n",
      "Episode 28, duration 11, epsilon 0.5553 done in 0.07467794418334961\n",
      "Episode 29, duration 19, epsilon 0.5458 done in 0.1348738670349121\n",
      "Episode 30, duration 12, epsilon 0.5399 done in 0.080108642578125\n",
      "Episode 31, duration 27, epsilon 0.5269 done in 0.18388104438781738\n",
      "Episode 32, duration 20, epsilon 0.5174 done in 0.14063215255737305\n",
      "Episode 33, duration 12, epsilon 0.5118 done in 0.08002090454101562\n",
      "Episode 34, duration 61, epsilon 0.4845 done in 0.4150106906890869\n",
      "Episode 35, duration 47, epsilon 0.4646 done in 0.31974029541015625\n",
      "Episode 36, duration 24, epsilon 0.4547 done in 0.16228890419006348\n",
      "Episode 37, duration 19, epsilon 0.4471 done in 0.1383509635925293\n",
      "Episode 38, duration 37, epsilon 0.4327 done in 0.2544131278991699\n",
      "Episode 39, duration 41, epsilon 0.4173 done in 0.28049206733703613\n",
      "Episode 40, duration 88, epsilon 0.3864 done in 0.6032016277313232\n",
      "Episode 41, duration 56, epsilon 0.3681 done in 0.47319889068603516\n",
      "Episode 42, duration 147, epsilon 0.3246 done in 1.0079312324523926\n",
      "Episode 43, duration 168, epsilon 0.2821 done in 1.1538841724395752\n",
      "Episode 44, duration 136, epsilon 0.2526 done in 0.939906120300293\n",
      "Episode 45, duration 200, epsilon 0.2159 done in 1.376744031906128\n",
      "Episode 46, duration 116, epsilon 0.1977 done in 0.8081269264221191\n",
      "Episode 47, duration 190, epsilon 0.1721 done in 1.310870885848999\n",
      "Episode 48, duration 133, epsilon 0.1569 done in 0.925858736038208\n",
      "Episode 49, duration 193, epsilon 0.1382 done in 1.339005947113037\n",
      "Episode 50, duration 144, epsilon 0.1263 done in 1.0117971897125244\n",
      "Episode 51, duration 173, epsilon 0.1142 done in 1.2044568061828613\n",
      "Episode 52, duration 199, epsilon 0.1026 done in 1.4039740562438965\n",
      "Episode 53, duration 129, epsilon 0.0963 done in 0.8904790878295898\n",
      "Episode 54, duration 130, epsilon 0.0906 done in 0.897730827331543\n",
      "Episode 55, duration 154, epsilon 0.0848 done in 1.057974100112915\n",
      "Episode 56, duration 200, epsilon 0.0785 done in 1.374563217163086\n",
      "Episode 57, duration 156, epsilon 0.0744 done in 1.0835351943969727\n",
      "Episode 58, duration 170, epsilon 0.0706 done in 1.1719176769256592\n",
      "Episode 59, duration 200, epsilon 0.0668 done in 1.3966801166534424\n",
      "Episode 60, duration 147, epsilon 0.0645 done in 1.0297768115997314\n",
      "Episode 61, duration 169, epsilon 0.0623 done in 1.1696279048919678\n",
      "Episode 62, duration 200, epsilon 0.0601 done in 1.3827219009399414\n",
      "Episode 63, duration 200, epsilon 0.0582 done in 1.3819458484649658\n",
      "Episode 64, duration 183, epsilon 0.0569 done in 1.2602739334106445\n",
      "Episode 65, duration 167, epsilon 0.0558 done in 1.1461822986602783\n",
      "Episode 66, duration 181, epsilon 0.0548 done in 1.2454109191894531\n",
      "Episode 67, duration 151, epsilon 0.0542 done in 1.0446162223815918\n",
      "Episode 68, duration 149, epsilon 0.0536 done in 1.0290651321411133\n",
      "Episode 69, duration 131, epsilon 0.0531 done in 0.9052600860595703\n",
      "Episode 70, duration 124, epsilon 0.0528 done in 0.8656771183013916\n",
      "Episode 71, duration 138, epsilon 0.0524 done in 0.9494469165802002\n",
      "Episode 72, duration 200, epsilon 0.0520 done in 1.3857600688934326\n",
      "Episode 73, duration 200, epsilon 0.0516 done in 1.3713972568511963\n",
      "Episode 74, duration 200, epsilon 0.0513 done in 1.3777101039886475\n",
      "Episode 75, duration 200, epsilon 0.0511 done in 1.387930154800415\n",
      "Episode 76, duration 199, epsilon 0.0509 done in 1.38106107711792\n",
      "Episode 77, duration 168, epsilon 0.0508 done in 1.1502282619476318\n",
      "Episode 78, duration 114, epsilon 0.0507 done in 0.8053157329559326\n",
      "Episode 79, duration 168, epsilon 0.0506 done in 1.1561789512634277\n",
      "Episode 80, duration 200, epsilon 0.0505 done in 1.3838837146759033\n",
      "Episode 81, duration 200, epsilon 0.0504 done in 1.3759219646453857\n",
      "Episode 82, duration 149, epsilon 0.0503 done in 1.0326650142669678\n",
      "Episode 83, duration 110, epsilon 0.0503 done in 0.762624979019165\n",
      "Episode 84, duration 98, epsilon 0.0503 done in 0.675915002822876\n",
      "Episode 85, duration 91, epsilon 0.0502 done in 0.6274607181549072\n",
      "Episode 86, duration 96, epsilon 0.0502 done in 0.6922199726104736\n",
      "Episode 87, duration 103, epsilon 0.0502 done in 0.7421529293060303\n",
      "Episode 88, duration 79, epsilon 0.0502 done in 0.5513300895690918\n",
      "Episode 89, duration 86, epsilon 0.0502 done in 0.5935618877410889\n",
      "Episode 90, duration 60, epsilon 0.0502 done in 0.41954994201660156\n",
      "Episode 91, duration 53, epsilon 0.0502 done in 0.3691830635070801\n",
      "Episode 92, duration 63, epsilon 0.0501 done in 0.43646693229675293\n",
      "Episode 93, duration 61, epsilon 0.0501 done in 0.4256327152252197\n",
      "Episode 94, duration 49, epsilon 0.0501 done in 0.3410658836364746\n",
      "Episode 95, duration 60, epsilon 0.0501 done in 0.42290210723876953\n",
      "Episode 96, duration 87, epsilon 0.0501 done in 0.6030490398406982\n",
      "Episode 97, duration 98, epsilon 0.0501 done in 0.6747057437896729\n",
      "Episode 98, duration 94, epsilon 0.0501 done in 0.6574912071228027\n",
      "Episode 99, duration 89, epsilon 0.0501 done in 0.6196060180664062\n",
      "Episode 100, duration 93, epsilon 0.0501 done in 0.6437051296234131\n",
      "Episode 101, duration 86, epsilon 0.0501 done in 0.5933897495269775\n",
      "Episode 102, duration 90, epsilon 0.0501 done in 0.6175668239593506\n",
      "Episode 103, duration 96, epsilon 0.0501 done in 0.6697330474853516\n",
      "Episode 104, duration 95, epsilon 0.0501 done in 0.6536321640014648\n",
      "Episode 105, duration 107, epsilon 0.0500 done in 0.7360389232635498\n",
      "Episode 106, duration 104, epsilon 0.0500 done in 0.7205400466918945\n",
      "Episode 107, duration 101, epsilon 0.0500 done in 0.6971189975738525\n",
      "Episode 108, duration 103, epsilon 0.0500 done in 0.7181408405303955\n",
      "Episode 109, duration 110, epsilon 0.0500 done in 0.7666049003601074\n",
      "Episode 110, duration 103, epsilon 0.0500 done in 0.7143807411193848\n",
      "Episode 111, duration 117, epsilon 0.0500 done in 0.8072812557220459\n",
      "Episode 112, duration 103, epsilon 0.0500 done in 0.7066538333892822\n",
      "Episode 113, duration 113, epsilon 0.0500 done in 0.770881175994873\n",
      "Episode 114, duration 109, epsilon 0.0500 done in 0.7433509826660156\n",
      "Episode 115, duration 126, epsilon 0.0500 done in 0.8728880882263184\n",
      "Episode 116, duration 125, epsilon 0.0500 done in 0.8539829254150391\n",
      "Episode 117, duration 115, epsilon 0.0500 done in 0.7866501808166504\n",
      "Episode 118, duration 128, epsilon 0.0500 done in 0.8968870639801025\n",
      "Episode 119, duration 117, epsilon 0.0500 done in 0.7894337177276611\n",
      "Episode 120, duration 119, epsilon 0.0500 done in 0.8069732189178467\n",
      "Episode 121, duration 121, epsilon 0.0500 done in 0.8292341232299805\n",
      "Episode 122, duration 126, epsilon 0.0500 done in 0.8628420829772949\n",
      "Episode 123, duration 128, epsilon 0.0500 done in 0.8701059818267822\n",
      "Episode 124, duration 127, epsilon 0.0500 done in 0.8643829822540283\n",
      "Episode 125, duration 128, epsilon 0.0500 done in 0.8670310974121094\n",
      "Episode 126, duration 133, epsilon 0.0500 done in 0.8988440036773682\n",
      "Episode 127, duration 132, epsilon 0.0500 done in 0.8985328674316406\n",
      "Episode 128, duration 123, epsilon 0.0500 done in 0.8396942615509033\n",
      "Episode 129, duration 122, epsilon 0.0500 done in 0.8346261978149414\n",
      "Episode 130, duration 129, epsilon 0.0500 done in 0.8732631206512451\n",
      "Episode 131, duration 127, epsilon 0.0500 done in 0.8619630336761475\n",
      "Episode 132, duration 125, epsilon 0.0500 done in 0.8601198196411133\n",
      "Episode 133, duration 130, epsilon 0.0500 done in 0.8926997184753418\n",
      "Episode 134, duration 149, epsilon 0.0500 done in 1.0162379741668701\n",
      "Episode 135, duration 146, epsilon 0.0500 done in 1.0144917964935303\n",
      "Episode 136, duration 155, epsilon 0.0500 done in 1.1010379791259766\n",
      "Episode 137, duration 145, epsilon 0.0500 done in 1.006847858428955\n",
      "Episode 138, duration 148, epsilon 0.0500 done in 1.0025711059570312\n",
      "Episode 139, duration 147, epsilon 0.0500 done in 1.0013279914855957\n",
      "Episode 140, duration 157, epsilon 0.0500 done in 1.0623958110809326\n",
      "Episode 141, duration 163, epsilon 0.0500 done in 1.246203899383545\n",
      "Episode 142, duration 167, epsilon 0.0500 done in 1.258746862411499\n",
      "Episode 143, duration 171, epsilon 0.0500 done in 1.3047959804534912\n",
      "Episode 144, duration 197, epsilon 0.0500 done in 1.5189218521118164\n",
      "Episode 145, duration 200, epsilon 0.0500 done in 1.3641529083251953\n",
      "Episode 146, duration 175, epsilon 0.0500 done in 1.1999869346618652\n",
      "Episode 147, duration 193, epsilon 0.0500 done in 1.3962912559509277\n",
      "Episode 148, duration 200, epsilon 0.0500 done in 1.4270689487457275\n",
      "Episode 149, duration 178, epsilon 0.0500 done in 1.3809239864349365\n",
      "Episode 150, duration 170, epsilon 0.0500 done in 1.2232329845428467\n",
      "Episode 151, duration 200, epsilon 0.0500 done in 1.358053207397461\n",
      "Episode 152, duration 200, epsilon 0.0500 done in 1.3574299812316895\n",
      "Episode 153, duration 200, epsilon 0.0500 done in 1.3650310039520264\n",
      "Episode 154, duration 200, epsilon 0.0500 done in 1.3595550060272217\n",
      "Episode 155, duration 200, epsilon 0.0500 done in 1.353254795074463\n",
      "Episode 156, duration 200, epsilon 0.0500 done in 1.3532416820526123\n",
      "Episode 157, duration 200, epsilon 0.0500 done in 1.3814971446990967\n",
      "Episode 158, duration 200, epsilon 0.0500 done in 1.3815040588378906\n",
      "Episode 159, duration 200, epsilon 0.0500 done in 1.5021710395812988\n",
      "Episode 160, duration 200, epsilon 0.0500 done in 1.6747369766235352\n",
      "Episode 161, duration 200, epsilon 0.0500 done in 1.512943983078003\n",
      "Episode 162, duration 200, epsilon 0.0500 done in 1.5327281951904297\n",
      "Episode 163, duration 200, epsilon 0.0500 done in 1.3624730110168457\n",
      "Episode 164, duration 200, epsilon 0.0500 done in 1.3636369705200195\n",
      "Episode 165, duration 200, epsilon 0.0500 done in 1.3668880462646484\n",
      "Episode 166, duration 200, epsilon 0.0500 done in 1.3623621463775635\n",
      "Episode 167, duration 200, epsilon 0.0500 done in 1.5403192043304443\n",
      "Episode 168, duration 200, epsilon 0.0500 done in 1.533285140991211\n",
      "Episode 169, duration 200, epsilon 0.0500 done in 1.6480047702789307\n",
      "Episode 170, duration 200, epsilon 0.0500 done in 1.3833022117614746\n",
      "Episode 171, duration 200, epsilon 0.0500 done in 1.551340103149414\n",
      "Episode 172, duration 200, epsilon 0.0500 done in 1.6012606620788574\n",
      "Episode 173, duration 200, epsilon 0.0500 done in 1.3564789295196533\n",
      "Episode 174, duration 200, epsilon 0.0500 done in 1.3708710670471191\n",
      "Episode 175, duration 200, epsilon 0.0500 done in 1.3697211742401123\n",
      "Episode 176, duration 200, epsilon 0.0500 done in 1.3770031929016113\n",
      "Episode 177, duration 200, epsilon 0.0500 done in 1.3645718097686768\n",
      "Episode 178, duration 200, epsilon 0.0500 done in 1.3577449321746826\n",
      "Episode 179, duration 200, epsilon 0.0500 done in 1.3617572784423828\n",
      "Episode 180, duration 200, epsilon 0.0500 done in 1.355118751525879\n",
      "Episode 181, duration 200, epsilon 0.0500 done in 1.4392738342285156\n",
      "Episode 182, duration 200, epsilon 0.0500 done in 1.3585059642791748\n",
      "Episode 183, duration 200, epsilon 0.0500 done in 1.3576688766479492\n",
      "Episode 184, duration 200, epsilon 0.0500 done in 1.3283789157867432\n",
      "Episode 185, duration 200, epsilon 0.0500 done in 1.3516929149627686\n",
      "Episode 186, duration 200, epsilon 0.0500 done in 1.3432908058166504\n",
      "Episode 187, duration 200, epsilon 0.0500 done in 1.30413818359375\n",
      "Episode 188, duration 200, epsilon 0.0500 done in 1.3096661567687988\n",
      "Episode 189, duration 200, epsilon 0.0500 done in 1.3109362125396729\n",
      "Episode 190, duration 200, epsilon 0.0500 done in 1.3352932929992676\n",
      "Episode 191, duration 179, epsilon 0.0500 done in 1.1698698997497559\n",
      "Episode 192, duration 172, epsilon 0.0500 done in 1.1208429336547852\n",
      "Episode 193, duration 200, epsilon 0.0500 done in 1.313204050064087\n",
      "Episode 194, duration 200, epsilon 0.0500 done in 1.2990899085998535\n",
      "Episode 195, duration 193, epsilon 0.0500 done in 1.2621419429779053\n",
      "Episode 196, duration 200, epsilon 0.0500 done in 1.3059780597686768\n",
      "Episode 197, duration 200, epsilon 0.0500 done in 1.310708999633789\n",
      "Episode 198, duration 200, epsilon 0.0500 done in 1.3115510940551758\n",
      "Episode 199, duration 200, epsilon 0.0500 done in 1.3044180870056152\n",
      "Episode 200, duration 200, epsilon 0.0500 done in 1.3019208908081055\n",
      "Episode 201, duration 200, epsilon 0.0500 done in 1.294126033782959\n",
      "Episode 202, duration 200, epsilon 0.0500 done in 1.314972162246704\n",
      "Episode 203, duration 8, epsilon 0.0500 done in 0.05160403251647949\n",
      "Episode 204, duration 10, epsilon 0.0500 done in 0.06728816032409668\n",
      "Episode 205, duration 10, epsilon 0.0500 done in 0.06553196907043457\n",
      "Episode 206, duration 45, epsilon 0.0500 done in 0.29355716705322266\n",
      "Episode 207, duration 200, epsilon 0.0500 done in 1.29243803024292\n",
      "Episode 208, duration 200, epsilon 0.0500 done in 1.30049729347229\n",
      "Episode 209, duration 19, epsilon 0.0500 done in 0.12517714500427246\n",
      "Episode 210, duration 172, epsilon 0.0500 done in 1.1186842918395996\n",
      "Episode 211, duration 117, epsilon 0.0500 done in 0.7614247798919678\n",
      "Episode 212, duration 200, epsilon 0.0500 done in 1.3088960647583008\n",
      "Episode 213, duration 200, epsilon 0.0500 done in 1.3115026950836182\n",
      "Episode 214, duration 200, epsilon 0.0500 done in 1.3104300498962402\n",
      "Episode 215, duration 200, epsilon 0.0500 done in 1.3032290935516357\n",
      "Episode 216, duration 200, epsilon 0.0500 done in 1.2945411205291748\n",
      "Episode 217, duration 200, epsilon 0.0500 done in 1.3055222034454346\n",
      "Episode 218, duration 200, epsilon 0.0500 done in 1.3371939659118652\n",
      "Episode 219, duration 200, epsilon 0.0500 done in 1.3848397731781006\n",
      "Episode 220, duration 200, epsilon 0.0500 done in 1.313049077987671\n",
      "Episode 221, duration 200, epsilon 0.0500 done in 1.5134639739990234\n",
      "Episode 222, duration 200, epsilon 0.0500 done in 1.381789207458496\n",
      "Episode 223, duration 200, epsilon 0.0500 done in 1.4158742427825928\n",
      "Episode 224, duration 200, epsilon 0.0500 done in 1.414707899093628\n",
      "Episode 225, duration 200, epsilon 0.0500 done in 1.4386420249938965\n",
      "Episode 226, duration 200, epsilon 0.0500 done in 1.341886043548584\n",
      "Episode 227, duration 200, epsilon 0.0500 done in 1.3163790702819824\n",
      "Episode 228, duration 200, epsilon 0.0500 done in 1.312330961227417\n",
      "Episode 229, duration 200, epsilon 0.0500 done in 1.3116211891174316\n",
      "Episode 230, duration 200, epsilon 0.0500 done in 1.2918107509613037\n",
      "Episode 231, duration 200, epsilon 0.0500 done in 1.316314935684204\n",
      "Episode 232, duration 200, epsilon 0.0500 done in 1.3044171333312988\n",
      "Episode 233, duration 200, epsilon 0.0500 done in 1.3119568824768066\n",
      "Episode 234, duration 200, epsilon 0.0500 done in 1.3020131587982178\n",
      "Episode 235, duration 200, epsilon 0.0500 done in 1.3022611141204834\n",
      "Episode 236, duration 200, epsilon 0.0500 done in 1.3033602237701416\n",
      "Episode 237, duration 200, epsilon 0.0500 done in 1.3114831447601318\n",
      "Episode 238, duration 200, epsilon 0.0500 done in 1.3066432476043701\n",
      "Episode 239, duration 200, epsilon 0.0500 done in 1.3090400695800781\n",
      "Episode 240, duration 200, epsilon 0.0500 done in 1.315540075302124\n",
      "Episode 241, duration 200, epsilon 0.0500 done in 1.3078739643096924\n",
      "Episode 242, duration 200, epsilon 0.0500 done in 1.509617805480957\n",
      "Episode 243, duration 200, epsilon 0.0500 done in 1.5250952243804932\n",
      "Episode 244, duration 200, epsilon 0.0500 done in 1.453706979751587\n",
      "Episode 245, duration 200, epsilon 0.0500 done in 1.4515478610992432\n",
      "Episode 246, duration 200, epsilon 0.0500 done in 1.4829621315002441\n",
      "Episode 247, duration 200, epsilon 0.0500 done in 1.472578763961792\n",
      "Episode 248, duration 200, epsilon 0.0500 done in 1.513437032699585\n",
      "Episode 249, duration 200, epsilon 0.0500 done in 1.4849259853363037\n",
      "Episode 250, duration 200, epsilon 0.0500 done in 1.4851951599121094\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "config = {}\n",
    "config['nb_hidden'] = 128 # number of hidden neurons in each layer\n",
    "config['batch_size'] = 128 # number of transitions sampled from the replay buffer\n",
    "config['gamma'] = 0.99 # discount factor\n",
    "config['eps_start'] = 0.9 # starting value of epsilon\n",
    "config['eps_end'] = 0.05 # final value of epsilon\n",
    "config['eps_decay'] = 1000 # rate of exponential decay of epsilon, higher means a slower decay\n",
    "config['learning_rate'] = 1e-3 # learning rate of the optimizer\n",
    "config['target_update_period'] = 120 # update period (in steps) of the target network\n",
    "config['buffer_limit'] = 10000 # maximum number of transitions in the replay buffer\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Create the agent\n",
    "agent = DQNAgent(env, config)\n",
    "\n",
    "# Train the agent\n",
    "agent.train(num_episodes=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Returns')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(agent.episode_durations)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** Training is very slow and unstable. Different runs lead to very different convergence profiles. There is much to improve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
